# Implementando nossa rede para classificar dígitos

## Exercício

> Tente criar uma rede neural com apenas duas camadas - uma de entrada e uma de saída, sem camadas escondidas - com 784 e 10 neurônios, respectivamente.
> Treine a rede utilizando gradiente descendente estocástico. Qual o valor da classificação que você consegue alcançar?

Anteriormente, eu pulei os detalhes sobre como os dados MNIST são carregados. É carregado de uma forma direta. Para ilustrar, aqui está o código. 
As estruturas de dados utilizadas para armazenar os dados MNIST são descritas nas strings de documentação - tuplas e listas de objetos `ndarray`
da biblioteca Numpy (pense neles como vetores se você não está familiarizado):

```
"""
mnist_loader
~~~~~~~~~~~~

Uma biblioteca para carregar os dados de imagens do MNIST. Para detalhes acerca das estruturas de dados que são retornadas,
consulte o doc ``load_data`` e ``load_data_wrapper``.  Na prática, ``load_data_wrapper`` é a função usualmente chamada pelo
nosso código.
"""

#### Libraries
# Standard library
import cPickle
import gzip

# Third-party libraries
import numpy as np

def load_data():
    """Retorna os dados MNIST como uma tupla contendo os dados de treinamento, validação e teste.  

    Os dados de treinamento são retornados como uma tupla ``training_data`` de duas entradas. A primeira entrada contém as imagens do treinamento, um ndarray
    numpy com 50000 entradas. Cada entrada é um ndarray com 784 valores, representando 28*28 pixels de uma única imagem do banco MNIST.  
    
    A segunda entrada na tupla ``training_data`` é um ndarray com 50000 entradas. Essas entradas são apenas os valores dos dígitos (0...9) para as imagens correspondentes
    à primeira entrada da tupla;
    
    Os dados ``validation_data`` e ``test_data`` são similares, exceto que cada um contém 10000 imagens.  

    Esse é um formato de dado bom, mas para utilizar em redes neurais, é melhor modificar o formato de ``training_data`` um pouco. Isso é feito na função do tipo
    wrapper ``load_data_wrapper()``, veja abaixo.  
    """
    f = gzip.open('../data/mnist.pkl.gz', 'rb')
    training_data, validation_data, test_data = cPickle.load(f)
    f.close()
    return (training_data, validation_data, test_data)

def load_data_wrapper():
    """Retorna a tupla que contém ``(training_data, validation_data,
    test_data)``. Baseada em ``load_data``, mas o formato é mais conveniente.  
    
    Em particular, ``training_data`` é uma lista contendo 50000 2-tuplas ``(x,y)``, 
    x é um numpy.ndarray de 784 dimensões que contém a imagem de entrada e ``y`` é o numpy.ndarray
    de 10 dimensões que representa o vetor unitário correspondente ao dígito certo de ``x``. `validation_data`` e ``test_data`` são listas contendo
    10000 2-tuplas ``(x, y)``. Em cada caso, ``x`` é um numpy.ndarray de 784 dimensões contendo a imagem de entrada e ``y`` é a correspondente classificação,
    os valores correspondentes a ``x`.  
    
    Obviamente, isso significa que nós estamos utilizando formatos ligeiramente diferentes para
    os dados de treinamento e de validação/teste. Esses formatos acabam sendo os mais convenientes de se utilizar na
    nossa rede neural.  
    tr_d, va_d, te_d = load_data()
    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
    training_results = [vectorized_result(y) for y in tr_d[1]]
    training_data = zip(training_inputs, training_results)
    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
    validation_data = zip(validation_inputs, va_d[1])
    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
    test_data = zip(test_inputs, te_d[1])
    return (training_data, validation_data, test_data)

def vectorized_result(j):
    """Retorna um vetor de 10 dimensões com 1.0 na posição j e zeros no resto. Isso é utilizado para converter um dígito na saída desejada.  
    """
    e = np.zeros((10, 1))
    e[j] = 1.0
    return e
```

Foi dito acima que nosso programa obtém resultados bons. O que isso significa? Bom comparado a o quê? É informativo ter algo simples
(de uma rede não neural) como teste base para comparar e compreender o que significa uma performance boa. A base mais simple de todas, 
claro, é supor um número randômico. Essa estratégia terá sucesso 10% do tempo. Nós estamos fazendo muito melhor que isso!  
Que tal uma base um pouco menos trivial? Vamos tentar uma ideia extremamente simples: iremos ver o quão escura uma imagem é. Por exemplo,
uma imagem de um 2 será tipicamente um pouco mais escura que a imagem de um 1, apenas porque um número maior de pixels é escuro, como
os próximos exemplos ilustram: 

<p align="center">
  <img src="https://user-images.githubusercontent.com/57269172/140234159-63d68da3-6a1b-4735-bd8a-c0b94cf988be.png" width="400"/><br>
  <b><i><a name="2.2"> Figure 1:</a></b> Exemplo dígitos MNIST.</i>
</p>



Isso sugere que utilizando os dados de treinamento para computar a média de pixels escuros para cada dígito 1, 2, 3,...,9. Quando apresentada
uma nova imagem, nós computamos o quão escura a imagem é, e então uma hipótese é formada para qual dígito tem uma média próxima. Esse
procedimento é simples, e fácil de realizar, de forma que não irei escrever explicitamente o código - se você está interessado, está no repositório do
[GitHub](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py). No entanto, é uma grande melhora em comparação à suposições randômicas, obtendo 2,225 de 10,000 imagens testadas equivale a
22,25% de precisão.  

Não é difícil encontrar outras ideias que alcançam uma precisão de 20% a 50%. Se você trabalhar um pouco mais você consegue chegar a 
acima de 50%. Mas para obter uma precisão muito maior, uma estratégia é utilizar algoritmos estabelecidos de machine learning.
Vamos tentar utilizar um dos mais conhecidos, o SVM. Se você não está familiarizado com SVM, não se preocupe, nós não precisaremos 
entender os detalhes de como SVM funciona. Em vez disso, vamos utilizar uma biblioteca de Python chamada [`scikit-learn`](https://scikit-learn.org/stable/), que provém uma 
interface simples em Python para uma biblioteca rápida em C para SVM chamada [`LIBSVM`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/).  

Se nós utilizarmos o classficador SVM de scikit-learn com as configurações padrão, então, será obtido 9,435 de 10,000 imagens corretas.
(O código está disponível [aqui](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py)). Esse é um grande avanço em comparação a nossa abordagem ingênua de classificar uma imagem baseado
em quão escura ela é. De fato, isso significa que o algoritmo SVM tem perfomance quase tão boa quanto nossas redes neurais, apenas um
pouco pior. Nos próximos capítulos nos vamos introduzir novas técnicas que nos permitem melhorar nossas redes neurais de forma que
elas tenham uma performance melhor que SVM. 

Entretanto, esse não é o final da história. O resultado 9,435 de 10,000 é obtido para os parâmetros padrões de SVM. O algoritmo tem um
número de parâmetros ajustáveis, e é possível encontrar parâmetros que melhorem essa performance. Eu não farei essa procura
explicitamente, mas mandarei você para esse [post](https://peekaboo-vision.blogspot.com/2010/09/mnist-for-ever.html) de [Andreas Mueller](https://peekaboo-vision.blogspot.com/) se você se interessar em saber mais. Mueller mostra que com
algum trabalho otimizando os parâmetros é possível chegar a uma performance de 98,5% de precisão. Em outras palavras, um SVM bem
parametrizado apenas faz um error de um dígito em 70. Isso é muito bom! Será que as redes neurais conseguem fazer melhor?

De fato, elas conseguem. Atualmente, redes neurais bem feitas supera, qualquer outra ténica para resolver MNIST, incluindo SVM. O recorde
atual (2013) foi a classificação de 9,979 de 10,000 imagens corretamente. Isso foi feito por Li Wan, [Matthew Zeiler](https://www.matthewzeiler.com/), Sixin Zhang, [Yann
LeCun](http://yann.lecun.com/) e [Rob Fergus](https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php). Nós veremos a maioria das técnicas utilizadas por ele nos próximos capítulos do livro. Naquele nível, a performance
se torna bem próxima da equivalente humana e é discutivelmente melhor, já que algumas das imagens do MNIST são difíceis para até
humanos reconhecerem com confiança, por exemplo: 


<p align="center">
  <img src="https://user-images.githubusercontent.com/57269172/140234241-77a2bf59-efd5-448c-a64d-c67f370af282.png" width="400"/><br>
  <b><i><a name="2.2"> Figure 1:</a></b> Exemplo dígitos MNIST.</i>
</p>


Eu confio que você concordará que essas imagens são difíceis de classificar! Com imagens como essa nos dados do MNIST é extraordinário que as
redes neurais conseguem classificar com precisão todas menos 21 do teste de 10000 imagens. Tipicamente, quando programamos, nós acreditamos
que resolver um problema complicado como reconhecer dígitos do MNIST requer um algoritmo complicado. Mas até as redes neurais no periódico
Wan et al apenas menciona algoritmos simples, variações dos algoritmos que foram vistos nesse capítulo. Toda a complexidade é compreendida
automaticamente pelos dados de treinamento. De alguma forma, a moral de ambos nossos resultados e nesses artigos sofisticados, é que para
alguns problemas:

```
algoritmo sofisticado <= algoritmo de aprendizagem simples + bons dados de treinamento
```
